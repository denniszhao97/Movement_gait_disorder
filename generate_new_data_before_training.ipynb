{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction model for gait data trail 1\n",
    "Richard Sowers r-sowers@illinois.edu https://publish.illinois.edu/r-sowers/ Copyright 2018 University of Illinois Board of Trustees. All Rights Reserved. Licensed under the MIT license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author Zhonghao(Dennis) Zhao\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read, clean, and sort data files\n",
    "# calculate speed average for trail 1, healthy\n",
    "\n",
    "health_exp_number = [300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,318,320,321,322,323]\n",
    "total_lengthh = len(health_exp_number)\n",
    "health_speed_mean_trail1 = np.zeros(total_lengthh)\n",
    "health_speed_std_trail1 = np.zeros(total_lengthh)\n",
    "index = 0\n",
    "trail_n = 1\n",
    "for exp_n in health_exp_number:\n",
    "    dataset = pd.read_csv(\"DATA/\"+str(exp_n)+\"_B3_TRIAL0\"+str(trail_n)+\"_GAITCYCLES.csv\")\n",
    "    valid_data = dataset[dataset.Valid == True] #use valid == true data only\n",
    "    Tor_data = valid_data[valid_data.EventType == \"TOR\"] # Get all tor data\n",
    "    Tol_data = valid_data[valid_data.EventType == \"TOL\"] # Get all tol data\n",
    "    Hsl_data = valid_data[valid_data.EventType == \"HSL\"] # Get all hsl data\n",
    "    Hsr_data = valid_data[valid_data.EventType == \"HSR\"] # Get all hsr data\n",
    "\n",
    "    # distance between one left step\n",
    "    Hsl_xList = [element.X for element in Hsl_data.itertuples()]\n",
    "    Hsl_yList = [element.Y for element in Hsl_data.itertuples()]\n",
    "    Hsl_timeList = [element.Time for element in Hsl_data.itertuples()]\n",
    "\n",
    "    Tol_xList = [element.X for element in Tol_data.itertuples()]\n",
    "    Tol_yList = [element.Y for element in Tol_data.itertuples()]\n",
    "    Tol_timeList = [element.Time for element in Tol_data.itertuples()]\n",
    "\n",
    "     # distance between one right step\n",
    "    HsR_xList = [element.X for element in Hsr_data.itertuples()]\n",
    "    HsR_yList = [element.Y for element in Hsr_data.itertuples()]\n",
    "    HsR_timeList = [element.Time for element in Hsr_data.itertuples()]\n",
    "\n",
    "    ToR_xList = [element.X for element in Tor_data.itertuples()]\n",
    "    ToR_yList = [element.Y for element in Tor_data.itertuples()]\n",
    "    ToR_timeList = [element.Time for element in Tor_data.itertuples()]\n",
    "    \n",
    "    length1 = min(len(Hsl_xList),len(Tol_xList))\n",
    "    length2 = min(len(HsR_xList),len(ToR_xList))\n",
    "    speed_array = np.zeros(length1+length2)\n",
    "    for i in range(0,length1): #euclidean distance between two points\n",
    "        distance = math.sqrt((Hsl_xList[i]-Tol_xList[i])**2 + (Hsl_yList[i]-Tol_yList[i])**2) \n",
    "        speed_array[i] = distance/(Hsl_timeList[i]-Tol_timeList[i])\n",
    "\n",
    "    for i in range(length1,length1 + length2): #euclidean distance between two points\n",
    "        distance = math.sqrt((HsR_xList[i-length1]-ToR_xList[i-length1])**2 + (HsR_yList[i-length1]-ToR_yList[i-length1])**2) \n",
    "        speed_array[i] = distance/(HsR_timeList[i-length1]-ToR_timeList[i-length1])\n",
    "\n",
    "    health_speed_mean_trail1[index] = speed_array.mean()\n",
    "    health_speed_std_trail1[index] = speed_array.std()\n",
    "\n",
    "    index += 1\n",
    "\n",
    "# Read, clean, and sort data files\n",
    "# calculate speed average for trail 1, patient\n",
    "\n",
    "patient_exp_number = list(range(200,220))\n",
    "total_lengthh = len(patient_exp_number)\n",
    "patient_speed_mean_trail1 = np.zeros(total_lengthh)\n",
    "patient_speed_std_trail1 = np.zeros(total_lengthh)\n",
    "index = 0\n",
    "trail_n = 1\n",
    "for exp_n in patient_exp_number:\n",
    "    dataset = pd.read_csv(\"DATA/\"+str(exp_n)+\"_B3_TRIAL0\"+str(trail_n)+\"_GAITCYCLES.csv\")\n",
    "    valid_data = dataset[dataset.Valid == True] #use valid == true data only\n",
    "    Tor_data = valid_data[valid_data.EventType == \"TOR\"] # Get all tor data\n",
    "    Tol_data = valid_data[valid_data.EventType == \"TOL\"] # Get all tol data\n",
    "    Hsl_data = valid_data[valid_data.EventType == \"HSL\"] # Get all hsl data\n",
    "    Hsr_data = valid_data[valid_data.EventType == \"HSR\"] # Get all hsr data\n",
    "\n",
    "    # distance between one left step\n",
    "    Hsl_xList = [element.X for element in Hsl_data.itertuples()]\n",
    "    Hsl_yList = [element.Y for element in Hsl_data.itertuples()]\n",
    "    Hsl_timeList = [element.Time for element in Hsl_data.itertuples()]\n",
    "\n",
    "    Tol_xList = [element.X for element in Tol_data.itertuples()]\n",
    "    Tol_yList = [element.Y for element in Tol_data.itertuples()]\n",
    "    Tol_timeList = [element.Time for element in Tol_data.itertuples()]\n",
    "\n",
    "     # distance between one right step\n",
    "    HsR_xList = [element.X for element in Hsr_data.itertuples()]\n",
    "    HsR_yList = [element.Y for element in Hsr_data.itertuples()]\n",
    "    HsR_timeList = [element.Time for element in Hsr_data.itertuples()]\n",
    "\n",
    "    ToR_xList = [element.X for element in Tor_data.itertuples()]\n",
    "    ToR_yList = [element.Y for element in Tor_data.itertuples()]\n",
    "    ToR_timeList = [element.Time for element in Tor_data.itertuples()]\n",
    "    \n",
    "    length1 = min(len(Hsl_xList),len(Tol_xList))\n",
    "    length2 = min(len(HsR_xList),len(ToR_xList))\n",
    "    speed_array = np.zeros(length1+length2)\n",
    "    for i in range(0,length1): #euclidean distance between two points\n",
    "        distance = math.sqrt((Hsl_xList[i]-Tol_xList[i])**2 + (Hsl_yList[i]-Tol_yList[i])**2) \n",
    "        speed_array[i] = distance/(Hsl_timeList[i]-Tol_timeList[i])\n",
    "\n",
    "    for i in range(length1,length1 + length2): #euclidean distance between two points\n",
    "        distance = math.sqrt((HsR_xList[i-length1]-ToR_xList[i-length1])**2 + (HsR_yList[i-length1]-ToR_yList[i-length1])**2) \n",
    "        speed_array[i] = distance/(HsR_timeList[i-length1]-ToR_timeList[i-length1])\n",
    "\n",
    "    patient_speed_mean_trail1[index] = speed_array.mean()\n",
    "    patient_speed_std_trail1[index] = speed_array.std()\n",
    "\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read, clean, and sort data files\n",
    "# list for all types strides' mean and std, will be update on each set of data for all health people\n",
    "\n",
    "health_exp_number = [300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,318,320,321,322,323]\n",
    "length = len(health_exp_number)\n",
    "xlaverage_array = np.zeros(length)\n",
    "yRaverage_array = np.zeros(length)\n",
    "xlaverage_std_array = np.zeros(length)\n",
    "yRaverage_std_array = np.zeros(length)\n",
    "trail_n = 1\n",
    "left_index = 0\n",
    "right_index = 0\n",
    "index = 0\n",
    "\n",
    "for exp_n in health_exp_number:\n",
    "    dataset = pd.read_csv(\"DATA/\"+str(exp_n)+\"_B3_TRIAL0\"+str(trail_n)+\"_GAITCYCLES.csv\")\n",
    "    valid_data = dataset[dataset.Valid == True] #use valid == true data only\n",
    "    Midl_data = valid_data[valid_data.EventType == \"MidSSL\"] # Get all midssl data\n",
    "    Midr_data = valid_data[valid_data.EventType == \"MidSSR\"] # Get all midssr data\n",
    "    total_xl = 0\n",
    "    total_yr = 0\n",
    "    count_l = 0\n",
    "    count_r = 0\n",
    "    \n",
    "    initial_counter = 0\n",
    "    normal_x = 0\n",
    "    for element in Midl_data.itertuples():\n",
    "        if(initial_counter < 3):\n",
    "            normal_x += element.X\n",
    "            initial_counter += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    normal_x = normal_x / 3\n",
    "    \n",
    "    all_x = []\n",
    "    for element in Midl_data.itertuples():\n",
    "        if(element.Time >= 30 and element.Time <= 60):\n",
    "            total_xl += (element.X - normal_x)\n",
    "            all_x.append(element.X - normal_x)\n",
    "            left_index += 1\n",
    "            count_l += 1\n",
    "    \n",
    "    xlaverage_array[index] = total_xl/count_l\n",
    "    temp_x = np.array(all_x)\n",
    "    xlaverage_std_array[index] = temp_x.std()\n",
    "    \n",
    "    initial_counter = 0\n",
    "    normal_y = 0\n",
    "    for element in Midr_data.itertuples():\n",
    "        if(initial_counter < 3):\n",
    "            normal_y += element.Y\n",
    "            initial_counter += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    normal_y = normal_y / 3\n",
    "    \n",
    "    all_y = []\n",
    "    for element in Midr_data.itertuples():\n",
    "        if(element.Time >= 30 and element.Time <= 60):\n",
    "            total_yr += (element.Y - normal_y)\n",
    "            all_y.append(element.Y - normal_y)\n",
    "            right_index += 1\n",
    "            count_r += 1\n",
    "    \n",
    "    yRaverage_array[index] = total_yr/count_r\n",
    "    temp_y = np.array(all_y)\n",
    "    yRaverage_std_array[index] = temp_y.std()\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "# Read, clean, and sort data files\n",
    "# list for all types strides' mean and std, will be update on each set of data for all patient people\n",
    "\n",
    "patient_exp_number = list(range(200,220))\n",
    "length = len(patient_exp_number)\n",
    "xlaverage_array_p = np.zeros(length)\n",
    "yRaverage_array_p = np.zeros(length)\n",
    "xlaverage_std_array_p = np.zeros(length)\n",
    "yRaverage_std_array_p = np.zeros(length)\n",
    "trail_n = 1\n",
    "left_index = 0\n",
    "right_index = 0\n",
    "index = 0\n",
    "\n",
    "for exp_n in health_exp_number:\n",
    "    dataset = pd.read_csv(\"DATA/\"+str(exp_n)+\"_B3_TRIAL0\"+str(trail_n)+\"_GAITCYCLES.csv\")\n",
    "    valid_data = dataset[dataset.Valid == True] #use valid == true data only\n",
    "    Midl_data = valid_data[valid_data.EventType == \"MidSSL\"] # Get all midssl data\n",
    "    Midr_data = valid_data[valid_data.EventType == \"MidSSR\"] # Get all midssr data\n",
    "    total_xl = 0\n",
    "    total_yr = 0\n",
    "    count_l = 0\n",
    "    count_r = 0\n",
    "    \n",
    "    initial_counter = 0\n",
    "    normal_x = 0\n",
    "    for element in Midl_data.itertuples():\n",
    "        if(initial_counter < 3):\n",
    "            normal_x += element.X\n",
    "            initial_counter += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    normal_x = normal_x / 3\n",
    "    \n",
    "    all_x = []\n",
    "    for element in Midl_data.itertuples():\n",
    "        if(element.Time >= 30 and element.Time <= 60):\n",
    "            total_xl += (element.X - normal_x)\n",
    "            all_x.append(element.X - normal_x)\n",
    "            left_index += 1\n",
    "            count_l += 1\n",
    "    \n",
    "    xlaverage_array_p[index] = total_xl/count_l\n",
    "    temp_x = np.array(all_x)\n",
    "    xlaverage_std_array_p[index] = temp_x.std()\n",
    "    \n",
    "    initial_counter = 0\n",
    "    normal_y = 0\n",
    "    for element in Midr_data.itertuples():\n",
    "        if(initial_counter < 3):\n",
    "            normal_y += element.Y\n",
    "            initial_counter += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    normal_y = normal_y / 3\n",
    "    \n",
    "    all_y = []\n",
    "    for element in Midr_data.itertuples():\n",
    "        if(element.Time >= 30 and element.Time <= 60):\n",
    "            total_yr += (element.Y - normal_y)\n",
    "            all_y.append(element.Y - normal_y)\n",
    "            right_index += 1\n",
    "            count_r += 1\n",
    "    \n",
    "    yRaverage_array_p[index] = total_yr/count_r\n",
    "    temp_y = np.array(all_y)\n",
    "    yRaverage_std_array_p[index] = temp_y.std()\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroid , wrote by Alan Yu mostly\n",
    "def centroid(array):\n",
    "    length = array.shape[0]\n",
    "    sum_x = np.sum(array[:, 0])\n",
    "    sum_y = np.sum(array[:, 1])\n",
    "    return sum_x/length, sum_y/length\n",
    "\n",
    "centroid_x_mean = np.zeros(len(health_exp_number))\n",
    "centroid_y_mean = np.zeros(len(health_exp_number))\n",
    "centroid_x_mean_p = np.zeros(len(patient_exp_number))\n",
    "centroid_y_mean_p = np.zeros(len(patient_exp_number))\n",
    "index = 0\n",
    "trial_n = 1\n",
    "\n",
    "for exp_n in health_exp_number:\n",
    "    dataset = pd.read_csv(\"DATA/\"+ str(exp_n)+\"_B3_TRIAL0\"+str(trial_n)+\"_GAITCYCLES.csv\")\n",
    "    valid_data = dataset[dataset.Valid == True]     \n",
    "    X_list = valid_data['X'].tolist()\n",
    "    Y_list = valid_data['Y'].tolist()\n",
    "    Event_list = valid_data['EventType'].tolist()\n",
    "    chunkX = [X_list[x:x+6] for x in range(0, len(X_list), 6)]\n",
    "    chunkY = [Y_list[y:y+6] for y in range(0, len(Y_list), 6)]\n",
    "    all_x = 0\n",
    "    all_y = 0\n",
    "    count = 0\n",
    "    \n",
    "    normal_x = 0\n",
    "    normal_y = 0\n",
    "    for stride in range(0, 3):\n",
    "        x = chunkX[stride]\n",
    "        y = chunkY[stride]\n",
    "        point = centroid(np.asarray(list(zip(chunkX[stride],chunkY[stride]))))\n",
    "        normal_x += point[0]\n",
    "        normal_y += point[1]\n",
    "        \n",
    "    normal_x = normal_x / 3\n",
    "    normal_y = normal_y / 3\n",
    "        \n",
    "        \n",
    "    for stride in range(0, len(chunkX)):\n",
    "        x = chunkX[stride]\n",
    "        y = chunkY[stride]\n",
    "        point = centroid(np.asarray(list(zip(chunkX[stride],chunkY[stride]))))\n",
    "        all_x += (point[0]-normal_x)\n",
    "        all_y += (point[1]-normal_y)\n",
    "        count += 1\n",
    "    \n",
    "    centroid_x_mean[index] = all_x / count\n",
    "    centroid_y_mean[index] = all_y / count\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "for exp_n in patient_exp_number:\n",
    "    dataset = pd.read_csv(\"DATA/\"+ str(exp_n)+\"_B3_TRIAL0\"+str(trial_n)+\"_GAITCYCLES.csv\")\n",
    "    valid_data = dataset[dataset.Valid == True]     \n",
    "    X_list = valid_data['X'].tolist()\n",
    "    Y_list = valid_data['Y'].tolist()\n",
    "    Event_list = valid_data['EventType'].tolist()\n",
    "    chunkX = [X_list[x:x+6] for x in range(0, len(X_list), 6)]\n",
    "    chunkY = [Y_list[y:y+6] for y in range(0, len(Y_list), 6)]\n",
    "    all_x = 0\n",
    "    all_y = 0\n",
    "    count = 0\n",
    "    \n",
    "    normal_x = 0\n",
    "    normal_y = 0\n",
    "    for stride in range(0, 3):\n",
    "        x = chunkX[stride]\n",
    "        y = chunkY[stride]\n",
    "        point = centroid(np.asarray(list(zip(chunkX[stride],chunkY[stride]))))\n",
    "        normal_x += point[0]\n",
    "        normal_y += point[1]\n",
    "        \n",
    "    normal_x = normal_x / 3\n",
    "    normal_y = normal_y / 3\n",
    "        \n",
    "        \n",
    "    for stride in range(0, len(chunkX)):\n",
    "        x = chunkX[stride]\n",
    "        y = chunkY[stride]\n",
    "        point = centroid(np.asarray(list(zip(chunkX[stride],chunkY[stride]))))\n",
    "        all_x += (point[0]-normal_x)\n",
    "        all_y += (point[1]-normal_y)\n",
    "        count += 1\n",
    "    \n",
    "    centroid_x_mean_p[index] = all_x / count\n",
    "    centroid_y_mean_p[index] = all_y / count\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    speed_average     x_std     y_std  centroid_x_mean  centroid_y_mean  type\n",
      "0        0.312231  0.023802  0.055501         0.010451         0.001079   1.0\n",
      "1        0.799317  0.025725  0.189369        -0.003654        -0.122884   1.0\n",
      "2        0.848669  0.018936  0.058246         0.003942        -0.301878   1.0\n",
      "3        0.984703  0.032018  0.052435        -0.021109         0.035680   1.0\n",
      "4        0.679221  0.033723  0.063301         0.017671        -0.378692   1.0\n",
      "5        0.748524  0.014873  0.078943        -0.003692         0.244060   1.0\n",
      "6        0.716259  0.020215  0.112323        -0.001007        -0.461554   1.0\n",
      "7        0.399000  0.033416  0.046177         0.002153         0.056925   1.0\n",
      "8        0.839027  0.017105  0.065189        -0.011357        -0.103979   1.0\n",
      "9        0.809139  0.017813  0.053065        -0.007957        -0.283112   1.0\n",
      "10       0.441429  0.008764  0.037097        -0.019338        -0.028920   1.0\n",
      "11       0.282007  0.034232  0.256984        -0.029857         0.574399   1.0\n",
      "12       0.552595  0.025578  0.068431         0.027478        -0.010361   1.0\n",
      "13       0.219372  0.021703  0.134695         0.000036         0.581911   1.0\n",
      "14       0.257180  0.015664  0.039481        -0.004772         0.179646   1.0\n",
      "15       0.200909  0.020800  0.068375        -0.001214         0.265133   1.0\n",
      "16       0.415683  0.025681  0.147735         0.006259         0.073472   1.0\n",
      "17       0.423552  0.023219  0.219737         0.033030         0.301846   1.0\n",
      "18       0.265978  0.016810  0.116343         0.002706         0.155417   1.0\n",
      "19       0.872057  0.017160  0.036653         0.029667        -0.017280   1.0\n",
      "20       0.539200  0.023802  0.055501        -0.004802         0.070966   0.0\n",
      "21       0.382062  0.025725  0.189369         0.002320         0.033120   0.0\n",
      "22       0.733529  0.018936  0.058246        -0.033605        -0.362484   0.0\n",
      "23       0.476451  0.032018  0.052435        -0.001686        -0.407324   0.0\n",
      "24       0.712904  0.033723  0.063301        -0.011811         0.227568   0.0\n",
      "25       0.790447  0.014873  0.078943         0.045694         0.378120   0.0\n",
      "26       0.683208  0.020215  0.112323         0.013717         0.052981   0.0\n",
      "27       0.441994  0.033416  0.046177        -0.005075        -0.287203   0.0\n",
      "28       0.654457  0.017105  0.065189        -0.029095         0.032242   0.0\n",
      "29       0.803144  0.017813  0.053065        -0.010191        -0.118646   0.0\n",
      "30       0.846743  0.008764  0.037097        -0.055794         0.333276   0.0\n",
      "31       0.888415  0.034232  0.256984        -0.002220        -0.805494   0.0\n",
      "32       0.886728  0.025578  0.068431         0.000027        -0.275387   0.0\n",
      "33       0.495065  0.021703  0.134695        -0.004584        -0.398441   0.0\n",
      "34       0.913980  0.015664  0.039481         0.003178        -0.309808   0.0\n",
      "35       0.518929  0.020800  0.068375         0.010542        -0.024247   0.0\n",
      "36       1.064163  0.025681  0.147735         0.019633        -0.634022   0.0\n",
      "37       0.546889  0.023219  0.219737        -0.011355        -0.165491   0.0\n",
      "38       1.028351  0.016810  0.116343        -0.026233        -0.836128   0.0\n",
      "39       0.811452  0.017160  0.036653        -0.004807        -0.163358   0.0\n"
     ]
    }
   ],
   "source": [
    "health = np.ones(len(health_exp_number))\n",
    "d = {'speed_average': health_speed_mean_trail1, 'x_std': xlaverage_std_array, 'y_std': yRaverage_std_array, \n",
    "    'centroid_x_mean': centroid_x_mean, 'centroid_y_mean': centroid_y_mean, 'type': health}\n",
    "new_data_h = pd.DataFrame(data=d)\n",
    "patient= np.zeros(len(health_exp_number))\n",
    "d2 = {'speed_average': patient_speed_mean_trail1, 'x_std': xlaverage_std_array_p, 'y_std': yRaverage_std_array_p, \n",
    "    'centroid_x_mean': centroid_x_mean_p, 'centroid_y_mean': centroid_y_mean_p, 'type': patient}\n",
    "new_data_p = pd.DataFrame(data=d2)\n",
    "\n",
    "new_data_trail1 = new_data_h.append(new_data_p, ignore_index = True)\n",
    "print(new_data_trail1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "labels = np.array(new_data_trail1['type'])\n",
    "new_data_trail1_2= new_data_trail1.drop(columns = 'type')\n",
    "feature_list = list(new_data_trail1_2.columns)\n",
    "features = np.array(new_data_trail1_2)\n",
    "\n",
    "train_features, test_features, train_label, test_label = train_test_split(features, labels , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 100 decision trees\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(train_features,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24395309 0.10451451 0.11198172 0.24710435 0.29244632]\n"
     ]
    }
   ],
   "source": [
    "a = clf.feature_importances_\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
